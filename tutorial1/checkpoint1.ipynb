{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2sjGhoFopAY"
      },
      "source": [
        "# Checkpoint 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU1iT8sWopAZ"
      },
      "source": [
        "Reminder:\n",
        "\n",
        "- You are being evaluated for completion and effort in this checkpoint.\n",
        "- Avoid manual labor / hard coding as much as possible, everything we've taught you so far are meant to simplify and automate your process.\n",
        "- Please do not remove any comment that starts with: \"# @@@\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSW9Fb5ropAZ"
      },
      "source": [
        "We will be working with the same `states_edu.csv` that you should already be familiar with from the tutorial.\n",
        "\n",
        "We investigated Grade 8 reading score in the tutorial. For this checkpoint, you are asked to investigate another test. Here's an overview:\n",
        "\n",
        "* Choose a specific response variable to focus on\n",
        ">Grade 4 Math, Grade 4 Reading, Grade 8 Math\n",
        "* Pick or create features to use\n",
        ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
        "* Explore the data as it relates to that test\n",
        ">Create at least 2 visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
        "* Create training and testing data\n",
        ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
        "* Train a ML model to predict outcome\n",
        ">Define what you want to predict, and pick a model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a>).\n",
        "\n",
        "\n",
        "Include comments throughout your code! Every cleanup and preprocessing task should be documented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtQPqn7ZopAa"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUgJRyNgopAa"
      },
      "source": [
        "<h2> Data Cleanup </h2>\n",
        "\n",
        "Import `numpy`, `pandas`, and `matplotlib`.\n",
        "\n",
        "(Feel free to import other libraries!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ZDWD7xopAa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSLmBz9hopAa"
      },
      "source": [
        "Load in the \"states_edu.csv\" dataset and take a look at the head of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz3wNzP6opAa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/states_edu.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjVgSzPoopAb"
      },
      "source": [
        "You should always familiarize yourself with what each column in the dataframe represents. Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDFX2-RnopAb"
      },
      "source": [
        "Use this space to rename columns, deal with missing data, etc. _(optional)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdcg5em3opAb"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "df.columns\n",
        "df.rename({\n",
        "    'GRADES_PK_G':'ENROLL_PREK',\n",
        "    'GRADES_KG_G':'ENROLL_KINDER',\n",
        "    'GRADES_4_G':'ENROLL_4',\n",
        "    'GRADES_8_G':'ENROLL_8',\n",
        "    'GRADES_12_G':'ENROLL_12',\n",
        "    'GRADES_1_8_G':'ENROLL_PRIMARY',\n",
        "    'GRADES_9_12_G':'ENROLL_HS',\n",
        "    'GRADES_ALL_G':'ENROLL_ALL',\n",
        "    'ENROLL':'ENROLL_ALL_EST'\n",
        "    },\n",
        "    axis=1,inplace=True)\n",
        "\n",
        "df.dropna(subset=\"AVG_MATH_8_SCORE\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez1RZc5hopAb"
      },
      "source": [
        "<h2>Exploratory Data Analysis (EDA) </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py3mM3htopAb"
      },
      "source": [
        "Chosen one of Grade 4 Reading, Grade 4 Math, or Grade 8 Math to focus on: Grade 8 Math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqeenTt4opAb"
      },
      "source": [
        "How many years of data are logged in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxQeIP4qopAb",
        "outputId": "df24d924-b33c-41c7-a9d6-953444eff355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n"
          ]
        }
      ],
      "source": [
        "# @@@ 1\n",
        "# Your Code\n",
        "print(df[\"YEAR\"].max() - df[\"YEAR\"].min())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezdktsyVttXP",
        "outputId": "4c420da8-7f9f-4e0c-9862-bedcd3b93864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PRIMARY_KEY', 'STATE', 'YEAR', 'ENROLL_ALL_EST', 'TOTAL_REVENUE',\n",
              "       'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
              "       'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE',\n",
              "       'SUPPORT_SERVICES_EXPENDITURE', 'OTHER_EXPENDITURE',\n",
              "       'CAPITAL_OUTLAY_EXPENDITURE', 'ENROLL_PREK', 'ENROLL_KINDER',\n",
              "       'ENROLL_4', 'ENROLL_8', 'ENROLL_12', 'ENROLL_PRIMARY', 'ENROLL_HS',\n",
              "       'ENROLL_ALL', 'AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE',\n",
              "       'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6lgrZ7SopAb"
      },
      "source": [
        "Let's compare Michigan to Ohio. Which state has the higher average across all years in the test you chose?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSZw99CuopAb",
        "outputId": "f48218d0-60ec-4288-8b68-13ec359e8fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276.1666666666667\n",
            "282.25\n",
            "\n",
            "Ohio\n"
          ]
        }
      ],
      "source": [
        "# @@@ 2\n",
        "michigan = df[df['STATE'] == 'MICHIGAN']\n",
        "lhio = df[df['STATE'] == 'OHIO']\n",
        "\n",
        "print(michigan['AVG_MATH_8_SCORE'].mean())\n",
        "print(lhio['AVG_MATH_8_SCORE'].mean())\n",
        "print(\"\\nOhio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xACCA4QopAc"
      },
      "source": [
        "Find the average for your chosen test across all states in 2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAUWojsPopAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158bb23e-a92e-46b9-a91e-a6524db92f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281.2641509433962\n"
          ]
        }
      ],
      "source": [
        "# @@@ 3\n",
        "print(df[df[\"YEAR\"] == 2019][\"AVG_MATH_8_SCORE\"].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqs1gzLRopAc"
      },
      "source": [
        "For each state, find a maximum value for your chosen test score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rUiiDbOopAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470f894a-6b0c-4bd7-9566-5e844bd940f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STATE\n",
            "ALABAMA                 269.0\n",
            "ALASKA                  283.0\n",
            "ARIZONA                 283.0\n",
            "ARKANSAS                279.0\n",
            "CALIFORNIA              277.0\n",
            "COLORADO                292.0\n",
            "CONNECTICUT             289.0\n",
            "DELAWARE                284.0\n",
            "DISTRICT_OF_COLUMBIA    269.0\n",
            "DODEA                   293.0\n",
            "FLORIDA                 281.0\n",
            "GEORGIA                 281.0\n",
            "HAWAII                  281.0\n",
            "IDAHO                   287.0\n",
            "ILLINOIS                285.0\n",
            "INDIANA                 288.0\n",
            "IOWA                    286.0\n",
            "KANSAS                  290.0\n",
            "KENTUCKY                282.0\n",
            "LOUISIANA               273.0\n",
            "MAINE                   289.0\n",
            "MARYLAND                288.0\n",
            "MASSACHUSETTS           301.0\n",
            "MICHIGAN                280.0\n",
            "MINNESOTA               295.0\n",
            "MISSISSIPPI             274.0\n",
            "MISSOURI                286.0\n",
            "MONTANA                 293.0\n",
            "NATIONAL                285.0\n",
            "NEBRASKA                288.0\n",
            "NEVADA                  278.0\n",
            "NEW_HAMPSHIRE           296.0\n",
            "NEW_JERSEY              296.0\n",
            "NEW_MEXICO              274.0\n",
            "NEW_YORK                283.0\n",
            "NORTH_CAROLINA          286.0\n",
            "NORTH_DAKOTA            293.0\n",
            "OHIO                    290.0\n",
            "OKLAHOMA                279.0\n",
            "OREGON                  285.0\n",
            "PENNSYLVANIA            290.0\n",
            "RHODE_ISLAND            284.0\n",
            "SOUTH_CAROLINA          282.0\n",
            "SOUTH_DAKOTA            291.0\n",
            "TENNESSEE               280.0\n",
            "TEXAS                   290.0\n",
            "UTAH                    287.0\n",
            "VERMONT                 295.0\n",
            "VIRGINIA                290.0\n",
            "WASHINGTON              290.0\n",
            "WEST_VIRGINIA           274.0\n",
            "WISCONSIN               289.0\n",
            "WYOMING                 289.0\n",
            "Name: AVG_MATH_8_SCORE, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# @@@ 4\n",
        "print(df.groupby(\"STATE\")[\"AVG_MATH_8_SCORE\"].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrzY1gv8opAc"
      },
      "source": [
        "*Refer to the `Grouping and Aggregating` section in Tutorial 0 if you are stuck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc0jf63GopAc"
      },
      "source": [
        "<h2> Feature Engineering </h2>\n",
        "\n",
        "After exploring the data, you can choose to modify features that you would use to predict the performance of the students on your chosen response variable.\n",
        "\n",
        "You can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
        "\n",
        "Use this space to modify or create features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fywsWcABopAc"
      },
      "outputs": [],
      "source": [
        "# @@@ 5\n",
        "df[\"support_per_student\"] = df[\"SUPPORT_SERVICES_EXPENDITURE\"] / df[\"ENROLL_8\"]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZh7v7aAopAc"
      },
      "source": [
        "Feature engineering justification: I added the expenditure_per_student column because I wanted to see if the amount the state invests into support for students in general affects the score of 8th grade math. The hypothesis is that the more the school expends on education and support resources in general, the higher scores are across the board"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wo5G5g_eS-QO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kzM9weopAc"
      },
      "source": [
        "<h2>Visualization</h2>\n",
        "\n",
        "Investigate the relationship between your chosen response variable and at least two predictors using visualizations. Write down your observations.\n",
        "\n",
        "**Visualization 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX06FYzBopAc"
      },
      "outputs": [],
      "source": [
        "# @@@ 6\n",
        "import matplotlib.pyplot as plt\n",
        "df.groupby(\"support_per_student\")[\"AVG_MATH_8_SCORE\"].mean().plot()\n",
        "plt.ylabel('SCORE')\n",
        "plt.title('Support per Student vs Avg Math Scores')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aahyhLOopAc"
      },
      "source": [
        "**<CAPTION FOR VIZ 1>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv3eob_RopAc"
      },
      "source": [
        "**Visualization 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFlFm9elopAc"
      },
      "outputs": [],
      "source": [
        "# @@@ 7\n",
        "df.groupby(\"AVG_READING_8_SCORE\")[\"AVG_MATH_8_SCORE\"].mean().plot()\n",
        "plt.ylabel('SCORE')\n",
        "plt.title('Avg Reading Scores vs Avg Math Scores')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbw9XnPdopAc"
      },
      "source": [
        "**<CAPTION FOR VIZ 2>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gekQKIoopAc"
      },
      "source": [
        "<h2> Data Creation </h2>\n",
        "\n",
        "_Use this space to create train/test data_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AusZndiopAd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMy2rvH6opAd"
      },
      "outputs": [],
      "source": [
        "# @@@ 8\n",
        "\n",
        "X = df[['support_per_student', 'AVG_READING_8_SCORE', 'AVG_READING_4_SCORE', 'ENROLL_8']].dropna()\n",
        "y = df.loc[X.index]['AVG_MATH_8_SCORE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpWzfSZMopAd"
      },
      "outputs": [],
      "source": [
        "# @@@ 9\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkFvkf3qopAd"
      },
      "source": [
        "<h2> Prediction </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjO4pS3nopAd"
      },
      "source": [
        "ML Models [Resource](https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuhzkhV9opAd"
      },
      "outputs": [],
      "source": [
        "# @@@ 10\n",
        "# import your sklearn class here\n",
        "from sklearn.linear_model import LinearRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cep0NMDGopAd"
      },
      "outputs": [],
      "source": [
        "# @@@ 11\n",
        "# create your model here\n",
        "model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCQTy-xpopAe"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yci4QenopAe"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dqQzoqBopAe"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN-W_72IopAe"
      },
      "source": [
        "Choose some metrics to evaluate the performance of your model, some of them are mentioned in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTSsM8dsopAe"
      },
      "outputs": [],
      "source": [
        "# @@@ 12\n",
        "print(f\"MAE: {np.mean(np.abs(model.predict(X_test) - y_test))}\")\n",
        "print(f\"R^2 Value: {model.score(X_test, y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrZn1wS9opAe"
      },
      "source": [
        "We have copied over the graphs that visualize the model's performance on the training and testing set.\n",
        "\n",
        "Change `col_name` and modify the call to `plt.ylabel()` to isolate how a single predictor affects the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX2Dn2vmopAe"
      },
      "outputs": [],
      "source": [
        "# @@@ 13\n",
        "\n",
        "col_name = 'AVG_READING_8_SCORE'\n",
        "\n",
        "\n",
        "f = plt.figure(figsize=(12,6))\n",
        "plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
        "plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
        "\n",
        "plt.legend(['True Training','Predicted Training'])\n",
        "plt.xlabel(col_name)\n",
        "plt.ylabel('Average 8 Reading Scores')\n",
        "plt.title(\"Model Behavior On Training Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M478eZfNopAe"
      },
      "outputs": [],
      "source": [
        "# @@@ 14\n",
        "\n",
        "\n",
        "col_name = 'support_per_student'\n",
        "\n",
        "\n",
        "f = plt.figure(figsize=(12,6))\n",
        "plt.scatter(X_test[col_name], y_test, color = \"blue\")\n",
        "plt.scatter(X_test[col_name], model.predict(X_test), color = \"black\")\n",
        "\n",
        "plt.legend(['True testing','Predicted testing'])\n",
        "plt.xlabel(col_name)\n",
        "plt.ylabel('Support Expenditure per Student')\n",
        "plt.title(\"Model Behavior on Testing Set\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYn406tFewgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6cf8df3ff69f85f626faf55c10df6fe2cb9d1236b4dc73844ee4dc01369c2c99"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}